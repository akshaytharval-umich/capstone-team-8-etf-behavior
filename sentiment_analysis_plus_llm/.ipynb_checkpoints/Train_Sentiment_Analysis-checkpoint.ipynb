{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d28b25e",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this project, we aim to develop and evaluate a sentiment analysis model based on financial articles related to specific companies. Our goal is to predict the sentiment of these articles (positive or negative) and see how these predictions correlate with the stock performance of a relevant Exchange Traded Fund (ETF). We use the powerful `Transformers` library by Hugging Face to leverage pre-trained language models like DistilBERT for this task.\n",
    "\n",
    "The process begins with data loading and preprocessing, followed by training the model on a portion of the data. We then evaluate the model's performance on a separate test set using various metrics like F1 score, precision, recall, and accuracy. The results will be analyzed using a confusion matrix and classification report to understand the model's effectiveness in capturing sentiment from financial texts. We also explore different variations in training, such as adjusting the text input length and incorporating advanced features like mixed precision training to optimize performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9383110",
   "metadata": {},
   "source": [
    "This code cell sets up the environment and imports necessary libraries for data processing, model training, and evaluation. We use `pandas` for data handling, `scikit-learn` for splitting data and computing evaluation metrics, and `transformers` for leveraging pre-trained language models. The `TEXT_COLUMN` variable is defined to specify whether we are working with summaries or full articles for sentiment analysis.\n",
    "\n",
    "To run this code, you may need to install the following libraries:\n",
    "- `pandas`: `pip install pandas`\n",
    "- `scikit-learn`: `pip install scikit-learn`\n",
    "- `transformers`: `pip install transformers`\n",
    "- `torch`: `pip install torch`\n",
    "- `matplotlib`: `pip install matplotlib`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcce245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, recall_score, precision_score, accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TEXT_COLUMN = \"Summary\"\n",
    "TEXT_COLUMN = \"full_article\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45273414",
   "metadata": {},
   "source": [
    "These functions handle data preprocessing and splitting for model training and evaluation. The `load_and_clean_data` function reads the input CSV file, removes rows with missing text data, and converts sentiment labels to numeric format. The `split_data` function divides the cleaned data into training, validation, and test sets, ensuring a balanced split for model development and evaluation. These steps are essential for preparing the data in a format suitable for machine learning tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to load and clean data\n",
    "Parameters:\n",
    "- file_path: Path to the CSV file\n",
    "- Returns: Cleaned DataFrame with relevant columns\n",
    "\"\"\"\n",
    "def load_and_clean_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.dropna(subset=[TEXT_COLUMN])\n",
    "    df['label'] = df['label'].map({'POSITIVE': 1, 'NEGATIVE': 0})\n",
    "    return df\n",
    "\n",
    "\"\"\"\n",
    "Function to split data into training, validation, and testing sets\n",
    "Parameters:\n",
    "- df: DataFrame with the cleaned data\n",
    "- Returns: Splits of training, validation, and testing sets\n",
    "\"\"\"\n",
    "def split_data(df):\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(df[TEXT_COLUMN], df['label'], test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110228d8",
   "metadata": {},
   "source": [
    "The `train_model` function is designed to build and train a sentiment analysis model using a specified pre-trained transformer model from Hugging Face. The function accepts several key parameters, including `model_name` (the name of the pre-trained model to be used), the training and validation datasets (`X_train`, `y_train`, `X_val`, `y_val`), and various hyperparameters such as `epochs`, `batch_size`, `warmup_steps`, and `weight_decay`.\n",
    "\n",
    "The function starts by initializing the tokenizer and model using the provided `model_name`. Depending on whether the input text is a summary or a full article, it tokenizes the data, truncating and padding sequences as necessary. A custom `SentimentDataset` class is defined to create PyTorch datasets for training and validation, which are then passed to a `Trainer` instance to manage the training process.\n",
    "\n",
    "The `TrainingArguments` class is used to configure various aspects of the training, including:\n",
    "- `output_dir`: Specifies where the trained model and other outputs will be saved.\n",
    "- `num_train_epochs`: Defines the number of epochs for training.\n",
    "- `per_device_train_batch_size` and `per_device_eval_batch_size`: Set the batch sizes for training and evaluation, respectively.\n",
    "- `warmup_steps`: The number of warmup steps for the learning rate scheduler.\n",
    "- `weight_decay`: The strength of weight decay to prevent overfitting.\n",
    "- `logging_dir` and `logging_steps`: Control where and how frequently training logs are stored.\n",
    "- `evaluation_strategy`: Determines when to evaluate the model, in this case, at the end of each epoch.\n",
    "- `fp16`: Enables mixed precision training to optimize memory usage and performance, particularly important when using full articles.\n",
    "- `learning_rate`: Specifies the learning rate for model optimization.\n",
    "\n",
    "After training, the model and tokenizer are saved for future use. The function also returns the training history, which includes detailed logs of the training process, allowing for analysis and troubleshooting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5737a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to build and train the model\n",
    "Parameters:\n",
    "- model_name: Name of the pre-trained model from Hugging Face\n",
    "- X_train: Training data\n",
    "- y_train: Training labels\n",
    "- X_val: Validation data\n",
    "- y_val: Validation labels\n",
    "- epochs: Number of training epochs (default: 3)\n",
    "- batch_size: Batch size for training and evaluation (default: 8)\n",
    "- warmup_steps: Number of warmup steps for learning rate scheduler (default: 500)\n",
    "- weight_decay: Strength of weight decay (default: 0.01)\n",
    "- Returns: Trained model and tokenizer\n",
    "\"\"\"\n",
    "def train_model(model_name, X_train, y_train, X_val, y_val, epochs=10, batch_size=8, warmup_steps=500, weight_decay=0.01):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "    if TEXT_COLUMN == \"full_article\":\n",
    "        train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, max_length=256)\n",
    "        val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, max_length=256)\n",
    "    else:\n",
    "        train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True)\n",
    "        val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True)\n",
    "\n",
    "    class SentimentDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, encodings, labels):\n",
    "            self.encodings = encodings\n",
    "            self.labels = labels\n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "            return item\n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "    train_dataset = SentimentDataset(train_encodings, y_train.tolist())\n",
    "    val_dataset = SentimentDataset(val_encodings, y_val.tolist())\n",
    "    if TEXT_COLUMN == \"full_article\":\n",
    "        fp16=True\n",
    "    else:\n",
    "        fp16=False\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        warmup_steps=warmup_steps,\n",
    "        weight_decay=weight_decay,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        fp16=fp16,\n",
    "        learning_rate=1e-5\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset\n",
    "    )\n",
    "    train_result = trainer.train()\n",
    "    model_save_path = f'./{model_name}_{TEXT_COLUMN}_sentiment_model_high_relevance'\n",
    "    model.save_pretrained(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    training_history = trainer.state.log_history\n",
    "    return model, tokenizer, training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388e1823",
   "metadata": {},
   "source": [
    "The `evaluate_model` function is designed to assess the performance of a trained sentiment analysis model on a test dataset. It takes several parameters:\n",
    "\n",
    "- `model`: The trained model to be evaluated.\n",
    "- `tokenizer`: The tokenizer used with the model for text processing.\n",
    "- `X_test`: The test data containing the input texts.\n",
    "- `y_test`: The true labels for the test data.\n",
    "- `batch_size`: The batch size used during evaluation (default is 8).\n",
    "\n",
    "The function begins by moving the model to the appropriate device (GPU if available, otherwise CPU) to optimize evaluation performance. It then processes the test data in batches to manage memory usage effectively, particularly when working with large datasets. Each batch of test data is tokenized and passed through the model to generate predictions.\n",
    "\n",
    "The predictions are then converted to class labels (0 or 1), which are compared to the true labels (`y_test`) to compute various evaluation metrics. The function calculates the confusion matrix and generates a classification report, providing detailed insights into the model's performance across different classes. Additionally, key performance metrics such as F1 score, recall, precision, and accuracy are computed and returned.\n",
    "\n",
    "These metrics allow for a comprehensive evaluation of the model's effectiveness in predicting sentiment, helping to identify areas of strength and potential improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23bc400",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function to evaluate the model\n",
    "Parameters:\n",
    "- model: Trained model\n",
    "- tokenizer: Tokenizer used with the model\n",
    "- X_test: Test data\n",
    "- y_test: Test labels\n",
    "- Returns: Confusion matrix, classification report, and performance metrics (f1 score, recall, precision, accuracy)\n",
    "\"\"\"\n",
    "def evaluate_model(model, tokenizer, X_test, y_test, batch_size=8):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    predictions = []\n",
    "    for i in range(0, len(X_test), batch_size):\n",
    "        batch = X_test[i:i + batch_size]\n",
    "        batch_encodings = tokenizer(batch.tolist(), truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch_encodings)\n",
    "        \n",
    "        batch_predictions = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "        predictions.extend(batch_predictions)\n",
    "\n",
    "    y_pred = [1 if pred == 1 else 0 for pred in predictions]\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return cm, report, f1, recall, precision, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8c3715",
   "metadata": {},
   "source": [
    "In this section, we bring together the functions defined earlier to build, train, and evaluate a sentiment analysis model using a pre-trained transformer. The process begins by loading and cleaning the dataset using the `load_and_clean_data` function, which reads the data from the specified file path and prepares it for training. If the input text is the full article (`TEXT_COLUMN` set to `\"full_article\"`), a sample of 80% of the data is taken to reduce the dataset size and optimize training time.\n",
    "\n",
    "Next, the dataset is split into training, validation, and test sets using the `split_data` function. These splits ensure that the model is trained on one portion of the data, validated on another during training, and finally evaluated on a separate test set.\n",
    "\n",
    "A list of pre-trained model names is provided, and in this example, we select the first model, `distilbert-base-uncased`, for training. The `train_model` function is then called with the selected model and the training and validation datasets. This function handles the entire training process, including setting up the tokenizer, configuring training arguments, and saving the trained model and tokenizer.\n",
    "\n",
    "Finally, the model is evaluated on the test set using the `evaluate_model` function (not shown in this block but referenced earlier), which calculates various performance metrics to assess how well the model predicts sentiment in unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f31bc17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model: distilbert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using cuda_amp half precision backend\n",
      "C:\\Users\\Akshay\\anaconda3\\envs\\autogluon\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 17113\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21400' max='21400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21400/21400 33:16, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.696900</td>\n",
       "      <td>0.692704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>0.671218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.501000</td>\n",
       "      <td>0.594909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.425600</td>\n",
       "      <td>0.618861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.464700</td>\n",
       "      <td>0.940498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.266600</td>\n",
       "      <td>1.265939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>1.458818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>1.598887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.028100</td>\n",
       "      <td>1.672779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>1.717540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./results\\checkpoint-500\n",
      "Configuration saved in ./results\\checkpoint-500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-1000\n",
      "Configuration saved in ./results\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-1000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-1500\n",
      "Configuration saved in ./results\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-1500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-2000\n",
      "Configuration saved in ./results\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-2000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3667\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results\\checkpoint-2500\n",
      "Configuration saved in ./results\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-2500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-3000\n",
      "Configuration saved in ./results\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-3000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-3500\n",
      "Configuration saved in ./results\\checkpoint-3500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-3500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-4000\n",
      "Configuration saved in ./results\\checkpoint-4000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-4000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3667\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results\\checkpoint-4500\n",
      "Configuration saved in ./results\\checkpoint-4500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-4500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-5000\n",
      "Configuration saved in ./results\\checkpoint-5000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-5000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-5500\n",
      "Configuration saved in ./results\\checkpoint-5500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-5500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-6000\n",
      "Configuration saved in ./results\\checkpoint-6000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-6000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3667\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results\\checkpoint-6500\n",
      "Configuration saved in ./results\\checkpoint-6500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-6500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-7000\n",
      "Configuration saved in ./results\\checkpoint-7000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-7000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-7500\n",
      "Configuration saved in ./results\\checkpoint-7500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-7500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-8000\n",
      "Configuration saved in ./results\\checkpoint-8000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-8000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-8500\n",
      "Configuration saved in ./results\\checkpoint-8500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-8500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3667\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results\\checkpoint-9000\n",
      "Configuration saved in ./results\\checkpoint-9000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-9000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-9500\n",
      "Configuration saved in ./results\\checkpoint-9500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-9500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-10000\n",
      "Configuration saved in ./results\\checkpoint-10000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-10000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-10500\n",
      "Configuration saved in ./results\\checkpoint-10500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-10500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3667\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results\\checkpoint-11000\n",
      "Configuration saved in ./results\\checkpoint-11000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-11000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-11500\n",
      "Configuration saved in ./results\\checkpoint-11500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-11500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-12000\n",
      "Configuration saved in ./results\\checkpoint-12000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-12000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-12500\n",
      "Configuration saved in ./results\\checkpoint-12500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-12500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3667\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results\\checkpoint-13000\n",
      "Configuration saved in ./results\\checkpoint-13000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-13000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-13500\n",
      "Configuration saved in ./results\\checkpoint-13500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-13500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-14000\n",
      "Configuration saved in ./results\\checkpoint-14000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-14000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-14500\n",
      "Configuration saved in ./results\\checkpoint-14500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-14500\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3667\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results\\checkpoint-15000\n",
      "Configuration saved in ./results\\checkpoint-15000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-15000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-15500\n",
      "Configuration saved in ./results\\checkpoint-15500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-15500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-16000\n",
      "Configuration saved in ./results\\checkpoint-16000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-16000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-16500\n",
      "Configuration saved in ./results\\checkpoint-16500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-16500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-17000\n",
      "Configuration saved in ./results\\checkpoint-17000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-17000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3667\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results\\checkpoint-17500\n",
      "Configuration saved in ./results\\checkpoint-17500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-17500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-18000\n",
      "Configuration saved in ./results\\checkpoint-18000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-18000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-18500\n",
      "Configuration saved in ./results\\checkpoint-18500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-18500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-19000\n",
      "Configuration saved in ./results\\checkpoint-19000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-19000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3667\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results\\checkpoint-19500\n",
      "Configuration saved in ./results\\checkpoint-19500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-19500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-20000\n",
      "Configuration saved in ./results\\checkpoint-20000\\config.json\n",
      "Model weights saved in ./results\\checkpoint-20000\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-20500\n",
      "Configuration saved in ./results\\checkpoint-20500\\config.json\n",
      "Model weights saved in ./results\\checkpoint-20500\\pytorch_model.bin\n",
      "Saving model checkpoint to ./results\\checkpoint-21000\n",
      "Configuration saved in ./results\\checkpoint-21000\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results\\checkpoint-21000\\pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3667\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Configuration saved in ./distilbert-base-uncased_full_article_sentiment_model_high_relevance\\config.json\n",
      "Model weights saved in ./distilbert-base-uncased_full_article_sentiment_model_high_relevance\\pytorch_model.bin\n",
      "tokenizer config file saved in ./distilbert-base-uncased_full_article_sentiment_model_high_relevance\\tokenizer_config.json\n",
      "Special tokens file saved in ./distilbert-base-uncased_full_article_sentiment_model_high_relevance\\special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Full_Data_Sentiment_Analysis_LLM_Output_ETF_value_Label.csv\"\n",
    "\n",
    "df = load_and_clean_data(file_path)\n",
    "if TEXT_COLUMN == \"full_article\":\n",
    "    df = df.sample(frac=0.8)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(df)\n",
    "\n",
    "model_names = [\n",
    "    \"distilbert-base-uncased\",\n",
    "#         \"bert-base-uncased\",\n",
    "#         \"roberta-base\",\n",
    "#         \"albert-base-v2\",\n",
    "#         \"xlnet-base-cased\"\n",
    "]\n",
    "\n",
    "model_name = model_names[0]\n",
    "print(f\"Training and evaluating model: {model_name}\")\n",
    "model, tokenizer, training_history = train_model(model_name, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d8c589",
   "metadata": {},
   "source": [
    "After training the model, we evaluate its performance on the test dataset using the `evaluate_model` function. This function returns several key metrics, including the confusion matrix, classification report, F1 score, recall, precision, and accuracy. These metrics provide a comprehensive understanding of how well the model performs in predicting sentiment.\n",
    "\n",
    "The confusion matrix shows the number of correct and incorrect predictions for each class, helping to visualize the model's strengths and weaknesses. The classification report provides additional details, including precision, recall, and F1 scores for each class. These metrics are critical for understanding the balance between precision and recall and how well the model handles both positive and negative sentiments.\n",
    "\n",
    "Finally, the overall F1 score, recall, precision, and accuracy metrics are printed, offering a quick summary of the model's performance. These results allow us to assess the effectiveness of the model in a real-world context and guide any necessary adjustments or improvements for future iterations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c95763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akshay\\AppData\\Local\\Temp\\ipykernel_10120\\1386814045.py:136: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  batch = X_test[i:i + batch_size]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for distilbert-base-uncased:\n",
      " [[1215  490]\n",
      " [ 441 1522]]\n",
      "Classification Report for distilbert-base-uncased:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72      1705\n",
      "           1       0.76      0.78      0.77      1963\n",
      "\n",
      "    accuracy                           0.75      3668\n",
      "   macro avg       0.75      0.74      0.74      3668\n",
      "weighted avg       0.75      0.75      0.75      3668\n",
      "\n",
      "F1 Score for distilbert-base-uncased: 0.7657861635220126\n",
      "Recall for distilbert-base-uncased: 0.7753438614365766\n",
      "Precision for distilbert-base-uncased: 0.7564612326043738\n",
      "Accuracy for distilbert-base-uncased: 0.7461832061068703\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cm, report, f1, recall, precision, accuracy = evaluate_model(model, tokenizer, X_test, y_test)\n",
    "print(f\"Confusion Matrix for {model_name}:\\n\", cm)\n",
    "print(f\"Classification Report for {model_name}:\\n\", report)\n",
    "print(f\"F1 Score for {model_name}: {f1}\")\n",
    "print(f\"Recall for {model_name}: {recall}\")\n",
    "print(f\"Precision for {model_name}: {precision}\")\n",
    "print(f\"Accuracy for {model_name}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "936709a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_name = f\"financial_sentiment_analysis_model_{model_name}.pt\"\n",
    "torch.save(model.state_dict(), model_save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45325c3",
   "metadata": {},
   "source": [
    "This block of code initializes the model architecture using the pre-trained transformer specified by `model_name` and prepares it for classification with two output labels. The model's state is then loaded from a previously saved file, restoring the trained parameters. Finally, the model is moved to the appropriate device (either GPU if available or CPU) to ensure optimal performance during inference or further training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3de017",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "model.load_state_dict(torch.load(model_save_name))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e5829f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ee4404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77add7bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3bc775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
